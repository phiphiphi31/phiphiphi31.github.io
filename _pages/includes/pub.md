
# üìù Publications (As the First Author)
## Visual models/Tracking on Video and Point Clouds

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ArXiv 2024</div><img src='images/sctrack2024a.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[QuadMamba: Learning Quadtree-based Selective Scan for Visual State Space Model](https://arxiv.org/pdf/2401.12743) \\
**Fei Xie**, Jiaohao Nie, Zhongdao Wang, Zhiwei He, Chao Ma.
- QuadMamba is a visual Mamba-based backbone network for classification, detection and segmentation.
- [CODE]
- [PDF]

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">T-PAMI</div><img src='images/supersbt2024a.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Correlation-Embedded Transformer Tracking:
A Single-Branch Framework](https://arxiv.org/pdf/2401.12743) \\
**Fei Xie**, Wankou Yang, Chunyu Wang, Lei Chu, Yue Cao, Chao Ma, Wenjun Zeng.
- SuperSBT improves our Single-Branch Tracking framework with a more specialized design.
- [CODE](https://github.com/phiphiphi31/SuperSBT)
- [PDF](https://arxiv.org/pdf/2401.12743)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/diffusiontrack2024a.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking](https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_DiffusionTrack_Point_Set_Diffusion_Model_for_Visual_Object_Tracking_CVPR_2024_paper.pdf) \\
**Fei Xie**, Zhongdao Wang, Chao Ma.
- DiffusionTrack is the first diffusion-based generative framework for visual object tracking.
- [CODE](https://github.com/phiphiphi31/DiffusionTrack)
- [PDF](https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_DiffusionTrack_Point_Set_Diffusion_Model_for_Visual_Object_Tracking_CVPR_2024_paper.pdf)
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2023</div><img src='images/videotrack2023a.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[VideoTrack: Learning to Track Objects via Video Transformer](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_VideoTrack_Learning_To_Track_Objects_via_Video_Transformer_CVPR_2023_paper.pdf) \\
**Fei Xie**, Lei Chu, Jiahao Li, Yan Lu and Chao Ma.
- VideoTrack is the first video backbone network for visual tracking.
- [CODE](https://github.com/phiphiphi31/VideoTrack)
- [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_VideoTrack_Learning_To_Track_Objects_via_Video_Transformer_CVPR_2023_paper.pdf)
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/sbt2022b.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Correlation-Aware Deep Tracking](https://arxiv.org/pdf/2203.01666) \\
**Fei Xie**, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.
- SBT is the first single-branch/one-stream transformer tracker that simplifies the Siamese tracking framework by using joint feature extraction and correlation.
- [CODE](https://github.com/phiphiphi31/SBT)
- [PDF](https://arxiv.org/pdf/2203.01666)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCVw 2021</div><img src='images/dualtfr2021b.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Learning Tracking Representations via Dual-Branch Fully Transformer Networks](https://arxiv.org/pdf/2112.02571) \\
**Fei Xie**, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.
- DualTFR is the first fully transformer-based tracking model that inspires researchers to adopt transformer-based feature extraction for tracking.
- [CODE](https://github.com/phiphiphi31/DualTFR)
- [PDF](https://arxiv.org/pdf/2112.02571)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCVw 2021</div><img src='images/samn2021a.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking](https://openaccess.thecvf.com/content/ICCV2021W/VOT/papers/Xie_Learning_Spatio-Appearance_Memory_Network_for_High-Performance_Visual_Tracking_ICCVW_2021_paper.pdf) \\
**Fei Xie**, Wankou Yang, Kaihua Zhang, Bo Liu, Guangting Wang, Wangmeng Zuo
- SAMN can simultaneously track objects and conduct segmentation.
- [CODE](https://github.com/phiphiphi31/DMB)
- [PDF](https://openaccess.thecvf.com/content/ICCV2021W/VOT/papers/Xie_Learning_Spatio-Appearance_Memory_Network_for_High-Performance_Visual_Tracking_ICCVW_2021_paper.pdf)
</div>
</div>
